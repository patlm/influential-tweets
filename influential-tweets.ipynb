{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influential Tweets Analysis\n",
    "\n",
    "Welcome to the influential Tweets analysis notebook! The analysis can be configured using the variables under the Configuration heading. The output for the project will be found under the Example heading at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from enum import Enum\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def importUsers(users_file):\n",
    "    users = []\n",
    "    \n",
    "    with open(users_file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for user in data['users']:\n",
    "            users.append(user['screen_name'])\n",
    "    \n",
    "    return users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "If dates are specified, the example will use the dates over num_tweets for choosing the tweets to look at. Set start_date and end_date to None to use num_tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file to import users from\n",
    "users_file = 'data/top-100.json' # other options include 'data/space-100.json' and 'data/finance-100.json'\n",
    "\n",
    "# List of users to analyze\n",
    "users = importUsers(users_file)\n",
    "\n",
    "# Date (inclusive) to start analyzing tweets of users\n",
    "# start_date = datetime.date(2020, 6, 15) # (year, month, day)\n",
    "start_date = datetime.datetime.today().date() - datetime.timedelta(days=3) # 3 days ago\n",
    "\n",
    "# Date (inclusive) to stop analyzing tweets of users\n",
    "# end_date = datetime.date(2020, 6, 15) # (year, month, day)\n",
    "end_date = datetime.datetime.today().date() # today\n",
    "\n",
    "# Number of most recent tweets to look at for each user (Max = ~3200)\n",
    "num_tweets = 20\n",
    "\n",
    "# Threshold at which to print tweet urls to the screen for the example\n",
    "threshold = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweepy Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables\n",
    "load_dotenv()\n",
    "consumer_key = os.getenv('CONSUMER_KEY')\n",
    "consumer_secret = os.getenv('CONSUMER_SECRET')\n",
    "\n",
    "# Set up tweepy with Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influential Tweets Class Definition\n",
    "\n",
    "The code block below contains the InfluentialTweetTracker class that hosts the logic for finding the commonly interacted with tweets between the different users. There are also two helper Enum classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetType(Enum):\n",
    "    TWEET = 1\n",
    "    RETWEET = 2\n",
    "    REPLY_TWEET = 3\n",
    "    QUOTE_TWEET = 4\n",
    "    \n",
    "class TweetSelectionType(Enum):\n",
    "    BY_NUMBER = 1\n",
    "    BY_DATES = 2\n",
    "\n",
    "class InfluentialTweetTracker:\n",
    "    # Dictionary such that key = tweet id and value = # of times tweet has been interacted with by different users\n",
    "    tweet_counts = {}\n",
    "\n",
    "    # Constructor for class\n",
    "    # If start_date and end_date are specified, will use that when determing range\n",
    "    # of tweets to consider. Otherwise will use the count parameter.\n",
    "    def __init__(self, users, count = 10, start_date = None, end_date = None):\n",
    "        self.users = users\n",
    "        \n",
    "        if start_date is not None and end_date is not None:\n",
    "            self.start_date = start_date\n",
    "            self.end_date = end_date\n",
    "            self.selection_type = TweetSelectionType.BY_DATES\n",
    "        else:\n",
    "            self.count = count\n",
    "            self.selection_type = TweetSelectionType.BY_NUMBER\n",
    "        \n",
    "    # Classifies type of tweet (returns TweetType enum)\n",
    "    def __classifyTweet(self, tweet):\n",
    "        if hasattr(tweet, 'retweeted_status'):\n",
    "            return TweetType.RETWEET\n",
    "        elif hasattr(tweet, 'quoted_status'):\n",
    "            return TweetType.QUOTE_TWEET\n",
    "        elif tweet.in_reply_to_status_id is not None:\n",
    "            return TweetType.REPLY_TWEET\n",
    "        else:\n",
    "            return TweetType.TWEET\n",
    "        \n",
    "    # If tweet at tweet_id does not exist in dictionary, creates a new entry, otherwise adds 1\n",
    "    def __addTweetToMap(self, tweet_id):\n",
    "        if tweet_id in self.tweet_counts:\n",
    "            self.tweet_counts[tweet_id] += 1\n",
    "        else: \n",
    "            self.tweet_counts[tweet_id] = 1\n",
    "            \n",
    "    def __getUserTimeline(self, user, count, max_id = None):\n",
    "        if max_id is not None:\n",
    "            return api.user_timeline(screen_name = user, count = count, tweet_mode = 'extended', max_id = max_id)\n",
    "        else:\n",
    "            return api.user_timeline(screen_name = user, count = count, tweet_mode = 'extended')\n",
    "    \n",
    "    # Gets number of recent tweets specified by count for user\n",
    "    # using custom paging because tweepy cursor.items(count) seemed\n",
    "    # to be getting tweets one at a time\n",
    "    def __getRecentTweetsByCount(self, user, count):\n",
    "        tweets = []\n",
    "        \n",
    "        if (count >= 200):\n",
    "            num_pages = count // 200\n",
    "            for i in range(0, num_pages):\n",
    "                if i == 0:\n",
    "                    tweets.extend(self.__getUserTimeline(user, 200))\n",
    "                else:\n",
    "                    tweets.extend(self.__getUserTimeline(user, 200, tweets[-1].id))\n",
    "        \n",
    "            num_remaining = count - 200 * num_pages        \n",
    "            if num_remaining > 0:\n",
    "                tweets.extend(self.__getUserTimeline(user, num_remaining, tweets[-1].id))\n",
    "        else:\n",
    "            tweets.extend(self.__getUserTimeline(user, count))\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    # Attempts to get all of the dates in the range using the users timelines\n",
    "    def __getTweetsByDates(self, user, start_date, end_date):\n",
    "        tweets = self.__getUserTimeline(user, 200)\n",
    "        \n",
    "        if len(tweets) > 0:\n",
    "            most_recent_tweet_date = tweets[0].created_at.date()\n",
    "            least_recent_tweet_date = tweets[-1].created_at.date()\n",
    "        \n",
    "        # Go far enough back into history to capture relevant tweets\n",
    "        while len(tweets) > 0 and start_date < least_recent_tweet_date:\n",
    "            tweets.extend(self.__getUserTimeline(user, 200, tweets[-1].id))\n",
    "            least_recent_tweet_date = tweets[-1].created_at.date()\n",
    "        \n",
    "        # Remove unwanted tweets from start\n",
    "        while len(tweets) > 0 and end_date < most_recent_tweet_date:\n",
    "            tweets.pop(0)\n",
    "            if len(tweets) > 0:\n",
    "                most_recent_tweet_date = tweets[0].created_at.date()\n",
    "        \n",
    "        # Remove unwanted tweets from end\n",
    "        while len(tweets) > 0 and start_date > least_recent_tweet_date:\n",
    "            tweets.pop()\n",
    "            if len(tweets) > 0:\n",
    "                least_recent_tweet_date = tweets[-1].created_at.date()\n",
    "        \n",
    "        return tweets\n",
    "        \n",
    "    # Main method that runs the analysis and returns the tweet_counts dictionary\n",
    "    def findInfluentialTweets(self):\n",
    "        self.tweet_counts = {}\n",
    "        \n",
    "        for user in self.users:\n",
    "            recent_tweets = None\n",
    "            \n",
    "            if self.selection_type == TweetSelectionType.BY_NUMBER:\n",
    "                recent_tweets = self.__getRecentTweetsByCount(user, self.count)\n",
    "            elif self.selection_type == TweetSelectionType.BY_DATES:\n",
    "                recent_tweets = self.__getTweetsByDates(user, self.start_date, self.end_date)\n",
    "            \n",
    "            for tweet in recent_tweets:\n",
    "                tweet_type = self.__classifyTweet(tweet)\n",
    "                \n",
    "                if tweet_type == TweetType.RETWEET:\n",
    "                    tweet_id = tweet.retweeted_status.id\n",
    "                    self.__addTweetToMap(tweet_id)\n",
    "                elif tweet_type == TweetType.QUOTE_TWEET:\n",
    "                    tweet_id = tweet.id\n",
    "                    tweet_quote_id = tweet.quoted_status.id\n",
    "                    self.__addTweetToMap(tweet_id)\n",
    "                    self.__addTweetToMap(tweet_quote_id)\n",
    "                elif tweet_type == TweetType.REPLY_TWEET:\n",
    "                    tweet_id = tweet.id\n",
    "                    tweet_reply_to_id = tweet.in_reply_to_status_id\n",
    "                    self.__addTweetToMap(tweet_id)\n",
    "                    self.__addTweetToMap(tweet_reply_to_id)\n",
    "                else:\n",
    "                    tweet_id = tweet.id\n",
    "                    self.__addTweetToMap(tweet_id)\n",
    "                \n",
    "        return self.tweet_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Below outputs links to the tweets above the threshold given the configuration specified under the Configuration heading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 207.68 s\n",
      "\n",
      "https://twitter.com/any/status/1278324680311681024 - 4\n",
      "https://twitter.com/any/status/1278176059876401152 - 4\n",
      "https://twitter.com/any/status/1278284552679624705 - 4\n",
      "https://twitter.com/any/status/1278040506908446721 - 4\n",
      "https://twitter.com/any/status/1277212069868318720 - 4\n",
      "https://twitter.com/any/status/1277215720418484224 - 4\n"
     ]
    }
   ],
   "source": [
    "tracker = InfluentialTweetTracker(users, count = num_tweets, start_date = start_date, end_date = end_date)\n",
    "start_time = time.time()\n",
    "influential_tweets = tracker.findInfluentialTweets()\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('Elapsed time: %.2f s\\n' % elapsed_time)\n",
    "for key in influential_tweets:\n",
    "    if influential_tweets[key] >= threshold:\n",
    "        print('https://twitter.com/any/status/%s - %s' % (key, influential_tweets[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
